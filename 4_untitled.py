# -*- coding: utf-8 -*-
"""4.Untitled

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10uK47yjrNCHOhi9eu6RvD-X06Psps0f1
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import kagglehub

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_score, recall_score, f1_score

# Set plot style
sns.set_style('whitegrid')

print("Downloading dataset")
path=kagglehub.dataset_download("redwankarimsony/heart-disease-data")
file_path=f'{path}/heart_disease_uci.csv'
df=pd.read_csv(file_path)
print("DataSet downloaded and loaded sucessfully.")
print(f"Data shape:{df.shape}")
df.head()

print("Data Information:")
df.info()
print("\nDescriptive Statistics:")
print(df.describe())
print("\nMissing Values:")
print(df.isnull().sum().sum())

df.isnull().sum()

plt.figure(figsize=(8,6))
sns.countplot(x='num',data=df,palette='viridis',hue='num',legend=False)
plt.title('Distribution of heart disease(1=Disease,0=No Disease)')
plt.xlabel('Target')
plt.ylabel('Count')
plt.show()

fig, axes = plt.subplots(2, 2, figsize=(18, 14))
fig.suptitle('Key Features vs. Heart Disease', fontsize=16)
sns.histplot(ax=axes[0, 0], data=df, x='age', hue='num', multiple='stack', palette='plasma').set_title('Age Distribution by Target')
sns.boxplot(ax=axes[0, 1], data=df, x='num', y='thalch', palette='magma', hue='num', legend=False).set_title('Max Heart Rate by Target')
cp_plot = sns.countplot(ax=axes[1, 0], data=df, x='cp', hue='num', palette='cividis')
cp_plot.set_title('Chest Pain Type by Target')
cp_plot.set_xticks(range(len(df['cp'].unique())))
cp_plot.set_xticklabels(['Typical Angina', 'Atypical Angina', 'Non-anginal Pain', 'Asymptomatic'])
sex_plot = sns.countplot(ax=axes[1, 1], data=df, x='sex', hue='num', palette='inferno')
sex_plot.set_title('Sex by Target')
sex_plot.set_xticks(range(len(df['sex'].unique())))
sex_plot.set_xticklabels(['Female', 'Male'])

plt.tight_layout(rect=[0, 0, 1, 0.96])
plt.show()

plt.figure(figsize=(16,12))
numerical_df=df.select_dtypes(include=np.number)
sns.heatmap(numerical_df.corr(),annot=True,cmap='coolwarm',fmt='.2f')
plt.title('Correlation Matrix of numerical features')
plt.show()

from sklearn.impute import SimpleImputer
X=df.drop('num',axis=1)
y=df['num']
X=X.drop(['id','dataset'],axis=1)
categorical_features = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'thal']
numerical_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak', 'ca']
numerical_transformer=Pipeline(steps=[('imputer',SimpleImputer(strategy='mean')),('scaler',StandardScaler())])
categorical_transformer=Pipeline(steps=[('imputer',SimpleImputer(strategy='most_frequent')),('onehot',OneHotEncoder(handle_unknown='ignore'))])
preprocessor=ColumnTransformer(transformers=[('num',numerical_transformer,numerical_features),('cat',categorical_transformer,categorical_features)])
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42,stratify=y)

from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
all_features=X_train.columns.tolist()
categorical_features=[col for col in all_features if X_train[col].dtype=='object']
numerical_features=[col for col in all_features if X_train[col].dtype !='object']
print("Numerical features:",numerical_features)
print("Categorical features:",categorical_features)
numeriacl_transformation=Pipeline(steps=[('imputer',SimpleImputer(strategy='mean')),('scaler',StandardScaler())])
categorical_transformation=Pipeline(steps=[('imputer',SimpleImputer(strategy='most_frequent')),('onehot',OneHotEncoder(handle_unknown='ignore'))])
preprocessor=ColumnTransformer(transformers=[('num',numeriacl_transformation,numerical_features),('cat',categorical_transformation,categorical_features)])
lr_pipeline=Pipeline(steps=[('preprocessor',preprocessor),('classifier',LogisticRegression(random_state=42))])
lr_pipeline.fit(X_train,y_train)
y_pred_lr=lr_pipeline.predict(X_test)

rf_pipeline=Pipeline(steps=[('preprocessor',preprocessor),('classifier',RandomForestClassifier(random_state=42))])
rf_pipeline.fit(X_train,y_train)
y_pred_rf=rf_pipeline.predict(X_test)

from sklearn.svm import SVC
svm_pipeline=Pipeline(steps=[('preprocessor',preprocessor),
                             ('classifier',SVC(random_state=42))])
svm_pipeline.fit(X_train,y_train)
y_pred_svm=svm_pipeline.predict(X_test)

from sklearn.neighbors import KNeighborsClassifier
knn_pipeline=Pipeline(steps=[('preprocessor',preprocessor),
                             ('classifier',KNeighborsClassifier())])
knn_pipeline.fit(X_train,y_train)
y_pred_knn=knn_pipeline.predict(X_test)

print("logistic regression")
print(classification_report(y_test,y_pred_lr,zero_division=0))
print("Random Forest")
print(classification_report(y_test,y_pred_rf,zero_division=0))
print("Support Vector Machine")
print(classification_report(y_test,y_pred_svm,zero_division=0))
print("KNN")
print(classification_report(y_test,y_pred_knn,zero_division=0))

from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

cm = confusion_matrix(y_test, y_pred_svm)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['No Disease', 'Disease', 'Severity 2', 'Severity 3', 'Severity 4'], yticklabels=['No Disease', 'Disease', 'Severity 2', 'Severity 3', 'Severity 4'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix - Support Vector Machine (SVM)')
plt.show()

feature_names=rf_pipeline.named_steps['preprocessor'].get_feature_names_out()
importances=rf_pipeline.named_steps['classifier'].feature_importances_
feature_importance_df=pd.DataFrame({'Feature':feature_names,'Importance':importances})
feature_importance_df=  feature_importance_df.sort_values(by='Importance',ascending=False).head(10)
plt.figure(figsize=(10,6))
sns.barplot(x='Importance',y='Feature',data=feature_importance_df,palette='rocket',hue='Feature',legend=False)
plt.title('top 10 most important faeture')
plt.show()